import os
import re
import json
import numpy as np
import requests
import string
from numpy.linalg import norm
from sentence_transformers import SentenceTransformer, CrossEncoder
from rank_bm25 import BM25Okapi

# --- 1. AYARLAR VE MODEL YÃœKLEMELERÄ° ---
# (Eski kodunla aynÄ±, burasÄ± veri tabanÄ± ve modelleri hazÄ±rlar)

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
EMBED_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" 
RERANKER_MODEL_NAME = "BAAI/bge-reranker-v2-m3" 
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "llama3.2:3b"

# Dosya yollarÄ± (Senin dosya isimlerin)
EMBED_FILE = "tbk_chunks_embeddings.npy"
META_FILE = "tbk_chunks_metadata.json"

print("ğŸ”„ Modeller ve veriler yÃ¼kleniyor...")

embed_model = SentenceTransformer(EMBED_MODEL_NAME)
reranker_model = CrossEncoder(RERANKER_MODEL_NAME, max_length=512)

# Verileri yÃ¼kle
embeddings = np.load(EMBED_FILE)
with open(META_FILE, "r", encoding="utf-8") as f:
    metadata = json.load(f)

# BM25 HazÄ±rlÄ±ÄŸÄ±
def simple_tokenizer(text):
    text = text.lower().translate(str.maketrans('', '', string.punctuation))
    return text.split()

tokenized_corpus = [simple_tokenizer(doc["text_preview"]) for doc in metadata]
bm25 = BM25Okapi(tokenized_corpus)

print("âœ… Sistem ve Veri TabanÄ± HazÄ±r!\n")


# --- 2. TEMEL ARAMA FONKSÄ°YONLARI (ESKÄ° KODUN) ---
# Bu fonksiyonlar "Motor" kÄ±smÄ±dÄ±r. ReAct ajanÄ± bunlarÄ± kullanacak.

def cosine_similarity(a, b):
    return float(np.dot(a, b) / (norm(a) * norm(b)))

def search_semantic(query, top_k=10):
    q_emb = embed_model.encode(query, convert_to_numpy=True)
    scores = []
    for i, emb in enumerate(embeddings):
        score = cosine_similarity(q_emb, emb)
        scores.append((i, score))
    return sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]

def search_bm25(query, top_k=10):
    tokenized_query = simple_tokenizer(query)
    doc_scores = bm25.get_scores(tokenized_query)
    scores = [(i, score) for i, score in enumerate(doc_scores)]
    return sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]

def hybrid_search_and_rerank(query, top_k_final=3):
    # 1. Semantic ve BM25 ile adaylarÄ± bul
    semantic_results = search_semantic(query, top_k=10)
    bm25_results = search_bm25(query, top_k=10)
    
    unique_indices = set([i for i, _ in semantic_results] + [i for i, _ in bm25_results])
    candidate_indices = list(unique_indices)
    
    if not candidate_indices:
        return []

    # 2. Rerank (Yeniden Puanlama)
    cross_inp = [[query, metadata[idx]["text_preview"]] for idx in candidate_indices]
    rerank_scores = reranker_model.predict(cross_inp)
    
    final_results = []
    for i, idx in enumerate(candidate_indices):
        final_results.append({
            "chunk_id": idx,
            "score": float(rerank_scores[i]),
            "text": metadata[idx]["text_preview"]
        })
    
    return sorted(final_results, key=lambda x: x["score"], reverse=True)[:top_k_final]


# --- 3. TOOL (ARAÃ‡) TANIMI (PROJE GEREKLÄ°LÄ°ÄÄ° ADIM 3.1) ---
# AjanÄ±n kullanacaÄŸÄ± "Tool" fonksiyonu.
# Ã–NEMLÄ°: Bu fonksiyon LLM cevabÄ± dÃ¶ndÃ¼rmez, ham bilgi (Observation) dÃ¶ndÃ¼rÃ¼r.

def kira_mevzuati_ara_tool(sorgu_metni):
    """
    Kira hukuku ve mevzuatÄ± hakkÄ±nda arama yapar.
    Girdi: Sorgu metni (string)
    Ã‡Ä±ktÄ±: Bulunan dÃ¶kÃ¼man metinleri (string)
    """
    print(f"\nğŸ” [TOOL Ã‡ALIÅIYOR] Sorgu: {sorgu_metni}")
    results = hybrid_search_and_rerank(sorgu_metni, top_k_final=3)
    
    if not results:
        return "Aranan konuda veritabanÄ±nda bilgi bulunamadÄ±."
    
    observation_text = ""
    for r in results:
        observation_text += f"---\n[DÃ¶kÃ¼man ParÃ§asÄ±]\n{r['text']}\n"
        
    return observation_text


# --- 4. REACT AJAN MÄ°MARÄ°SÄ° (PROJE GEREKLÄ°LÄ°ÄÄ° ADIM 3.2) ---
# BurasÄ± "Beyin" kÄ±smÄ±dÄ±r.

SYSTEM_PROMPT = """
Sen uzman bir Kira Hukuku AsistanÄ±sÄ±n. GÃ¶revin sorulan sorulara net cevap vermektir.

ELÄ°NDEKÄ° ARAÃ‡LAR:
1. kira_mevzuati_ara: Kira kanunu ile ilgili bilgi arar.

TAKÄ°P ETMEN GEREKEN FORMAT:
Soru: KullanÄ±cÄ±nÄ±n sorusu
Thought: CevabÄ± biliyor muyum? Bilmiyorsam hangi aracÄ± kullanmalÄ±yÄ±m?
Action: kira_mevzuati_ara: "aranacak kelimeler"
Observation: (Buraya arama sonucu gelecek)
Thought: Gelen bilgiyi okudum. Cevap bu metinde var mÄ±? Varsa Final Answer yaz.
Final Answer: Sorunun cevabÄ± (TÃ¼rkÃ§e).

Ã‡OK Ã–NEMLÄ° KURALLAR:
1. EÄER "Observation" kÄ±smÄ±nda bilgi gÃ¶rÃ¼yorsan, TEKRAR ARAMA YAPMA. Hemen "Final Answer" yaz.
2. "Action:" yazarken sadece `kira_mevzuati_ara: "kelime"` formatÄ±nÄ± kullan. BaÅŸka bir ÅŸey yazma.
3. Asla kendi kendine Observation uydurma.
"""

def ask_ollama(prompt):
    """Ollama API'sine istek atar."""
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False,
        "options": {"temperature": 0, "stop": ["Observation:"]} # Observation'Ä± modelin uydurmasÄ±nÄ± engelle
    }
    try:
        response = requests.post(OLLAMA_URL, json=payload)
        return response.json()["response"]
    except Exception as e:
        return f"Hata: {e}"

def react_loop(user_question):
    conversation_history = f"{SYSTEM_PROMPT}\n\nSoru: {user_question}\n"
    max_turns = 5
    turn_count = 0
    
    # Modelin daha Ã¶nce yaptÄ±ÄŸÄ± aramalarÄ± hafÄ±zada tutalÄ±m (Loop engellemek iÃ§in)
    previous_actions = []

    print(f"\nğŸ¤– [AJAN] '{user_question}' sorusu Ã¼zerine dÃ¼ÅŸÃ¼nmeye baÅŸladÄ±...\n")

    while turn_count < max_turns:
        turn_count += 1
        
        response = ask_ollama(conversation_history)
        response = response.strip()
        print(f"\n--- AdÄ±m {turn_count} ---")
        print(response)
        
        conversation_history += f"{response}\n"

        if "Final Answer:" in response:
            return response.split("Final Answer:")[-1].strip()

        # Action Yakalama
        action_match = re.search(r"Action:\s*(\w+):\s*\"?([^\"]+)\"?", response)
        
        if action_match:
            tool_name = action_match.group(1)
            query = action_match.group(2).strip()
            
            # --- YENÄ° EKLENEN GÃœVENLÄ°K Ã–NLEMÄ° ---
            # EÄŸer bu aramayÄ± daha Ã¶nce yaptÄ±ysa engelle!
            if query in previous_actions:
                observation = "UYARI: Bu aramayÄ± zaten yaptÄ±n ve yukarÄ±da sonuÃ§larÄ± var. Tekrar arama yapma! YukarÄ±daki metni oku ve 'Final Answer' ver."
                print(f"âš ï¸ [LOOP ENGELENDÄ°] Model aynÄ± ÅŸeyi ({query}) tekrar aramak istedi.")
            else:
                # Yeni bir arama ise Ã§alÄ±ÅŸtÄ±r
                if tool_name == "kira_mevzuati_ara":
                    observation = kira_mevzuati_ara_tool(query)
                    previous_actions.append(query) # Listeye ekle
                else:
                    observation = f"Hata: {tool_name} diye bir araÃ§ yok. Sadece 'kira_mevzuati_ara' kullanabilirsin."
            
            observation_str = f"Observation: {observation}\n"
            conversation_history += observation_str
            
        else:
            # Action yoksa ve Final Answer da yoksa, model saÃ§malamÄ±ÅŸ olabilir.
            # Ona zorla cevap vermesini sÃ¶yleyelim.
            if turn_count == max_turns:
                 return "ÃœzgÃ¼nÃ¼m, dÃ¶ngÃ¼ye girdim. LÃ¼tfen soruyu tekrar sor."
            
    return "Maksimum adÄ±m sayÄ±sÄ±na ulaÅŸÄ±ldÄ± (Cevap bulunamadÄ±)."


# --- 5. ANA Ã‡ALIÅTIRMA BLOÄU ---
if __name__ == "__main__":
    while True:
        print("\n" + "="*60)
        q = input("Soru Sor (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): ").strip()
        if q.lower() == 'q': break
        
        final_response = react_loop(q)
        
        print("\nğŸ¯ [SONUÃ‡]:")
        print(final_response)